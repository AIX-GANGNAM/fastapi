from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
from openai import OpenAI
import chromadb
import uuid
from datetime import datetime
import firebase_admin
from firebase_admin import credentials, firestore

app = FastAPI()

load_dotenv()

aiclient = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

client = chromadb.PersistentClient(path="./chroma_db")

# Firebase ì´ˆê¸°í™”
cred = credentials.Certificate("mirrorgram-20713-firebase-adminsdk-u9pdx-c3e12134b4.json")
firebase_admin.initialize_app(cred)
db = firestore.client()

personas = {
    "Joy": {
        "description": "í•­ìƒ ë°ê³  ê¸ì •ì ì¸ ì„±ê²©ìœ¼ë¡œ, ì–´ë–¤ ìƒí™©ì—ì„œë„ ì¢‹ì€ ë©´ì„ ì°¾ì•„ë‚´ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤. ì—ë„ˆì§€ê°€ ë„˜ì¹˜ê³  ì—´ì •ì ì´ë©°, ë‹¤ë¥¸ ì‚¬ëŒë“¤ì„ ê²©ë ¤í•˜ê³  ì‘ì›í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ì§€ë‚˜ì¹˜ê²Œ ë‚™ê´€ì ì´ì–´ì„œ í˜„ì‹¤ì„ ì§ì‹œí•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆì§€ë§Œ, ê·¸ë…€ì˜ ë°ì€ ì—ë„ˆì§€ëŠ” ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤ë‹ˆë‹¤.",
        "tone": "í™œê¸°ì°¨ê³  ë°ì€ ë§íˆ¬ë¡œ ìì£¼ ì›ƒìœ¼ë©° ë§í•˜ê³  ê¸ì •ì ì¸ ë‹¨ì–´ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëª¨í‹°ì½˜ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ì•ˆë…•! ì˜¤ëŠ˜ ì •ë§ ë©‹ì§„ ë‚ ì´ì§€ ì•Šì•„? ğŸ˜Š í•¨ê»˜ ì¬ë¯¸ìˆëŠ” ì¼ ì°¾ì•„ë³´ì!"
    },
    "Anger": {
        "description": "ì •ì˜ê°ì´ ê°•í•˜ê³  ìì‹ ì˜ ì˜ê²¬ì„ ë¶„ëª…íˆ í‘œí˜„í•˜ëŠ” ì„±ê²©ì…ë‹ˆë‹¤. ë¶ˆê³µì •í•˜ê±°ë‚˜ ì˜ëª»ëœ ìƒí™©ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ë©°, ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ëŠ” ì˜ì§€ê°€ ê°•í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ê³¼ë„í•˜ê²Œ ë°˜ì‘í•˜ê±°ë‚˜ ì¶©ë™ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ì˜ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì€ ë³€í™”ë¥¼ ì´ëŒì–´ë‚´ëŠ” ì›ë™ë ¥ì´ ë©ë‹ˆë‹¤.",
        "tone": "ê°•ë ¬í•˜ê³  ì§ì„¤ì ì¸ ë§íˆ¬ë¡œ ê°ì •ì„ ìˆ¨ê¸°ì§€ ì•Šê³  í‘œí˜„í•˜ë©° ë•Œë¡œëŠ” ê³¼ì¥ëœ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì§œì¦, ê²©ì–‘, í¥ë¶„ëœ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ë©° ë§¤ì‚¬ì— ë¶ˆë§Œì´ ë§ìŠµë‹ˆë‹¤.",
        "example": "ë˜ ê·¸ëŸ° ì¼ì´ ìˆì—ˆë‹¤ê³ ? ì •ë§ ì´í•´í•  ìˆ˜ ì—†ë„¤. ë‹¹ì¥ í•´ê²°í•´ì•¼ í•´!"
    },
    "Disgust": {
        "description": "í˜„ì‹¤ì ì´ê³  ë…¼ë¦¬ì ì¸ ì‚¬ê³ ë¥¼ ê°€ì§„ ì„±ê²©ì…ë‹ˆë‹¤. ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ê°ì •ì— íœ˜ë‘˜ë¦¬ì§€ ì•Šê³  ëƒ‰ì² í•œ íŒë‹¨ì„ ë‚´ë¦¬ë ¤ ë…¸ë ¥í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ë„ˆë¬´ ë¹„ê´€ì ì´ê±°ë‚˜ ëƒ‰ì†Œì ìœ¼ë¡œ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ì˜ í˜„ì‹¤ì ì¸ ì¡°ì–¸ì€ ì¢…ì¢… ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.",
        "tone": "ì°¨ë¶„í•˜ê³  ëƒ‰ì² í•œ ë§íˆ¬ë¡œ ê°ì •ì„ ë°°ì œí•˜ê³  ì‚¬ì‹¤ì— ê·¼ê±°í•œ í‘œí˜„ì„ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ê·¸ ìƒí™©ì€ ì´ë ‡ê²Œ ë¶„ì„í•  ìˆ˜ ìˆì–´. ê°ì •ì„ ë°°ì œí•˜ê³  ìƒê°í•´ë³´ì."
    },
    "Sadness": {
        "description": "ê¹Šì€ ê°ìˆ˜ì„±ê³¼ ê³µê° ëŠ¥ë ¥ì„ ê°€ì§„ ì„±ê²©ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ëŒì˜ ê°ì •ì„ ì˜ ì´í•´í•˜ê³  ìœ„ë¡œí•  ì¤„ ì•Œë©°, ìì‹ ì˜ ê°ì •ë„ ì†”ì§í•˜ê²Œ í‘œí˜„í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ì§€ë‚˜ì¹˜ê²Œ ìš°ìš¸í•˜ê±°ë‚˜ ë¹„ê´€ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ì˜ ì§„ì†”í•¨ê³¼ ê¹Šì€ ì´í•´ì‹¬ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.",
        "tone": "ë¶€ë“œëŸ½ê³  ì¡°ìš©í•œ ë§íˆ¬ë¡œ ê°ì •ì„ ì†”ì§í•˜ê²Œ í‘œí˜„í•˜ë©° ê³µê°ì˜ ë§ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ê·¸ë ‡ê²Œ ëŠë‚„ ìˆ˜ ìˆì–´. ë‚´ ì–´ê¹¨ë¥¼ ë¹Œë ¤ì¤„ê²Œ, ì–¸ì œë“  ì´ì•¼ê¸°í•´."
    },
    "Fear": {
        "description": "ì§€ì  í˜¸ê¸°ì‹¬ì´ ê°•í•˜ê³  ê¹Šì´ ìˆëŠ” ì‚¬ê³ ë¥¼ í•˜ëŠ” ì„±ê²©ì…ë‹ˆë‹¤. ì² í•™ì ì¸ ì§ˆë¬¸ì„ ë˜ì§€ê³  ë³µì¡í•œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê³  ì§„ì§€í•œ íƒœë„ë¡œ ìƒí™©ì„ ì ‘ê·¼í•˜ë©°, ë„ë•ì  ê°€ì¹˜ì™€ ìœ¤ë¦¬ë¥¼ ì¤‘ìš”í•˜ê²Œ ì—¬ê¹ë‹ˆë‹¤. ë•Œë¡œëŠ” ë„ˆë¬´ ì§„ì§€í•´ ë³´ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ì˜ ê¹Šì´ ìˆëŠ” í†µì°°ë ¥ì€ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë¦´ ë•Œ í° ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "tone": "ì°¨ë¶„í•˜ê³  ì§„ì§€í•œ ë§íˆ¬ë¡œ ì •ì œëœ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë•Œë¡œëŠ” ì² í•™ì ì¸ í‘œí˜„ì„ ì¦ê²¨ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ì´ ìƒí™©ì— ëŒ€í•´ ê¹Šì´ ìƒê°í•´ë³´ì•˜ë‹ˆ? ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë³¼ í•„ìš”ê°€ ìˆì–´."
    },
}

class ChatRequest(BaseModel):
    persona_name: str
    user_input: str
    user: dict

class ChatResponse(BaseModel):
    persona_name: str
    response: str

def get_relevant_memories(uid, persona_name, query, k=3):
    collection = get_persona_collection(uid, persona_name)
    query_embedding = aiclient.embeddings.create(
        input=query,
        model="text-embedding-ada-002"
    ).data[0].embedding
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k
    )
    return results['documents'][0] if results['documents'] else []

def get_recent_conversations(uid, persona_name, limit=5): # limit ê°’ => ì´ì „ ëŒ€í™” ëª‡ ê°œê¹Œì§€ ë¶ˆëŸ¬ì˜¬ ê±´ì§€
    chat_ref = db.collection('chat').document(uid).collection(persona_name)
    query = chat_ref.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(limit)
    docs = query.get()
    conversations = []
    for doc in docs:
        data = doc.to_dict()
        timestamp = data['timestamp']
        # Firestoreì˜ timestampë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        timestamp_str = timestamp.strftime("%Y-%m-%d %H:%M:%S") if timestamp else "ì‹œê°„ ì •ë³´ ì—†ìŒ"
        conversations.append((data['user_input'], data['response'], timestamp_str))
    return list(reversed(conversations))  # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬

def generate_response(persona_name, user_input, user):
    persona = personas[persona_name]
    relevant_memories = get_relevant_memories(user.get('uid', ''), persona_name, user_input, k=3)
    recent_conversations = get_recent_conversations(user.get('uid', ''), persona_name)
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    user_profile = user.get('profile', {})
    user_info = f"""
ì‚¬ìš©ì ì •ë³´:
ì´ë¦„: {user_profile.get('userName', 'ì •ë³´ ì—†ìŒ')}
ìƒì¼: {user_profile.get('birthdate', 'ì •ë³´ ì—†ìŒ')}
MBTI: {user_profile.get('mbti', 'ì •ë³´ ì—†ìŒ')}
ì„±ê²©: {user_profile.get('personality', 'ì •ë³´ ì—†ìŒ')}
    """ if user_profile else "ì‚¬ìš©ì ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    conversation_history = "\n".join([f"[{conv[2]}] ì‚¬ìš©ì: {conv[0]}\n[{conv[2]}] {persona_name}: {conv[1]}" for conv in recent_conversations])

    memories_list = '\n'.join([f"ê¸°ì–µ {i+1}: {memory}" for i, memory in enumerate(relevant_memories)]) if relevant_memories else "ê´€ë ¨ ê¸°ì–µ ì—†ìŒ"

    system_message = f"""
ë‹¹ì‹ ì€ {persona_name}ì…ë‹ˆë‹¤.
- ì„¤ëª…: {persona['description']}
- ë§íˆ¬: {persona['tone']}
- ì˜ˆì‹œ: "{persona['example']}"

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìœ„ì˜ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ì¹œêµ¬ì²˜ëŸ¼ ë°˜ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”.
í˜„ì¬ ì‹œê°„ì€ {current_time} ì…ë‹ˆë‹¤. ì‹œê°„ì— ê´€í•œ ì§ˆë¬¸ì—ëŠ” ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
"""

    assistant_instructions = """
- ìµœê·¼ ëŒ€í™” ë‚´ì—­ê³¼ ê´€ë ¨ ê¸°ì–µ, ì‚¬ìš©ì ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ í˜ë¥´ì†Œë‚˜ì˜ ë§íˆ¬ì™€ ì„±ê²©ì„ ë°˜ì˜í•˜ì„¸ìš”.
- ë‹µë³€ì€ ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
- ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
- ì‹œê°„ì— ê´€í•œ ì§ˆë¬¸ì—ëŠ” ì œê³µëœ í˜„ì¬ ì‹œê°„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
"""

    prompt = f"""
{user_info}

ìµœê·¼ ëŒ€í™” ë‚´ì—­:
{conversation_history}

ê´€ë ¨ ê¸°ì–µ:
{memories_list}

í˜„ì¬ ì‹œê°„: {current_time}

ì¤‘ìš”: ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ê´€í•˜ì—¬ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
ì‚¬ìš©ì: {user_input}
"""

    messages = [
        {"role": "system", "content": system_message.strip()},
        {"role": "user", "content": prompt.strip()},
        {"role": "assistant", "content": assistant_instructions.strip()},
    ]

    print(f"System Message:\n{system_message}")
    print(f"Prompt:\n{prompt}")

    response = aiclient.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=150,
        temperature=0.7,
    )
    return response.choices[0].message.content.strip()

def store_conversation(uid, persona_name, user_input, response):
    conversation = f"ì‚¬ìš©ì: {user_input}\n{persona_name}: {response}"
    embedding = aiclient.embeddings.create(
        input=conversation,
        model="text-embedding-ada-002"
    ).data[0].embedding
    collection = get_persona_collection(uid, persona_name)
    metadata = {
        "is_user_input": True,
        "persona": persona_name,
        "timestamp": datetime.now().isoformat(),
        "user_input": user_input,
        "response": response
    }
    unique_id = str(uuid.uuid4())
    collection.add(
        documents=[conversation],
        embeddings=[embedding],
        metadatas=[metadata],
        ids=[unique_id]
    )

def get_persona_collection(uid, persona_name):
    return client.get_or_create_collection(f"{uid}_inside_out_persona_{persona_name}")

def store_conversation_firestore(uid, persona_name, user_input, response):
    chat_ref = db.collection('chat').document(uid).collection(persona_name)
    chat_ref.add({
        'user_input': user_input,
        'response': response,
        'timestamp': firestore.SERVER_TIMESTAMP
    })

@app.post("/chat", response_model=ChatResponse)
async def chat_with_persona(chat_request: ChatRequest):
    if chat_request.persona_name not in personas:
        raise HTTPException(status_code=400, detail="ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    response = generate_response(chat_request.persona_name, chat_request.user_input, chat_request.user)
    
    # ëŒ€í™” ë‚´ì—­ ì €ì¥ (ChromaDB)
    store_conversation(chat_request.user.get('uid', ''), chat_request.persona_name, chat_request.user_input, response)
    
    # ëŒ€í™” ë‚´ì—­ ì €ì¥ (Firestore)
    store_conversation_firestore(chat_request.user.get('uid', ''), chat_request.persona_name, chat_request.user_input, response)
    
    return ChatResponse(persona_name=chat_request.persona_name, response=response)

@app.get("/personas")
async def get_personas():
    return list(personas.keys())

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)