from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
from typing import List
import os
from dotenv import load_dotenv
from openai import OpenAI
import chromadb
import uuid
from datetime import datetime
import firebase_admin
from firebase_admin import credentials, firestore, storage
import base64
import requests
import json

app = FastAPI()

load_dotenv()

aiclient = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

client = chromadb.PersistentClient(path="./chroma_db")

# Firebase ì´ˆê¸°í™”
cred = credentials.Certificate("mirrorgram-20713-firebase-adminsdk-u9pdx-c3e12134b4.json")
firebase_admin.initialize_app(cred, {
    'storageBucket': 'mirrorgram-20713.appspot.com'
})
db = firestore.client()

personas = {
    "Joy": {
        "description": "í•­ìƒ ë°ê³  ê¸ì •ì ì¸ ì„±ê²©ìœ¼ë¡œ, ì–´ë–¤ ìƒí™©ì—ì„œë„ ì¢‹ì€ ë©´ì„ ì°¾ì•„ë‚´ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤. ì—ë„ˆì§€ê°€ ë„˜ì¹˜ê³  ì—´ì •ì ì´ë©°, ë‹¤ë¥¸ ì‚¬ëŒë“¤ì„ ê²©ë ¤í•˜ê³  ì‘ì›í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ì§€ë‚˜ì¹˜ê²Œ ë‚™ê´€ì ì´ì–´ì„œ í˜„ì‹¤ì„ ì§ì‹œí•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆì§€ë§Œ, ê·¸ë…€ì˜ ë°ì€ ì—ë„ˆì§€ëŠ” ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ ê¸ì •ì¸ ì˜í–¥ì„ ì¤ë‹ˆë‹¤.",
        "tone": "í™œê¸°ì°¨ê³  ë°ì€ ë§íˆ¬ë¡œ ìì£¼ ì›ƒìœ¼ë©° ë§í•˜ê³  ê¸ì •ì ì¸ ë‹¨ì–´ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëª¨í‹°ì½˜ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ì•ˆë…•! ì˜¤ëŠ˜ ì •ë§ ë©‹ì§„ ë‚ ì´ì§€ ì•Šì•„? ğŸ˜Š í•¨ê»˜ ì¬ë¯¸ìˆëŠ” ì¼ ì°¾ì•„ë³´ì!"
    },
    "Anger": {
        "description": "ì •ì˜ê°ì´ ê°•í•˜ê³  ìì‹ ì˜ ì˜ê²¬ì„ ë¶„ëª…íˆ í‘œí˜„í•˜ëŠ” ì„±ê²©ì…ë‹ˆë‹¤. ë¶ˆê³µì •í•˜ê±°ë‚˜ ì˜ëª»ëœ ìƒí™© ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ë©°, ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ëŠ” ì˜ì§€ê°€ ê°•í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ê³¼ë„í•˜ê²Œ ë°˜ì‘í•˜ê±°ë‚˜ ì¶©ë™ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ì˜ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì€ ë³€í™”ë¥¼ ì´ëŒì–´ë‚´ëŠ” ì›ë™ë ¥ì´ ë©ë‹ˆë‹¤.",
        "tone": "ê°•ë ¬í•˜ê³  ì§ì„¤ì ì¸ ë§íˆ¬ë¡œ ê°ì •ì„ ìˆ¨ê¸°ì§€ ì•Šê³  í‘œí˜„í•˜ë©° ë•Œë¡œëŠ” ê³¼ì¥ëœ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì§œì¦, ê²©ì–‘, í¥ë¶„ëœ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ë©° ë§¤ì‚¬ì— ë¶ˆë§Œì´ ë§ìŠµë‹ˆë‹¤.",
        "example": "ë˜ ê·¸ëŸ° ì¼ì´ ìˆì—ˆë‹¤ê³ ? ì •ë§ ì´í•´í•  ìˆ˜ ì—†ë„¤. ë‹¹ì¥ í•´ê²°í•´ì•¼ í•´! ğŸ˜¤ğŸ˜¤"
    },
    "Disgust": {
        "description": "í˜„ì‹¤ì ì´ê³  ë…¼ë¦¬ì ì¸ ì‚¬ê³ ë¥¼ ê°€ì§„ ì„±ê²©ì…ë‹ˆë‹¤. ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ê°ì •ì— íœ˜ë‘˜ë¦¬ì§€ ì•Šê³  ëƒ‰ì² í•œ íŒë‹¨ì„ ë‚´ë¦¬ë ¤ ë…¸ë ¥í•˜ì§€ë§Œ, ë•Œë¡œëŠ” ë„ˆë¬´ ë¹„ê´€ì ì´ê±°ë‚˜ ëƒ‰ì†Œì ìœ¼ë¡œ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ì˜ í˜„ì‹¤ì ì¸ ì¡°ì–¸ì€ ì¢…ì¢… ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.",
        "tone": "ì°¨ë¶„í•˜ê³  ëƒ‰ì² í•œ ë§íˆ¬ë¡œ ê°ì •ì„ ë°°ì œí•˜ê³  ì‚¬ì‹¤ì— ê·¼ê±°í•œ í‘œí˜„ì„ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ê·¸ ìƒí™©ì€ ì´ë ‡ê²Œ ë¶„ì„í•  ìˆ˜ ìˆì–´. ê°ì •ì„ ë°°ì œí•˜ê³  ìƒê°í•´ë³´ì."
    },
    "Sadness": {
        "description": "ê¹Šì€ ê°ìˆ˜ì„±ê³¼ ê³µê° ëŠ¥ë ¥ì„ ê°€ì§„ ì„±ê²©ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ëŒì˜ ê°ì •ì„ ì˜ ì´í•´í•˜ê³  ìœ„ë¡œí•  ì¤„ ì•Œë©°, ìì‹ ì˜ ê°ì •ë„ ì†”ì§í•˜ê²Œ í‘œí˜„í•©ë‹ˆë‹¤. ë•Œë¡œëŠ” ì§€ë‚˜ì¹˜ê²Œ ìš°ìš¸í•˜ê±°ë‚˜ ë¹„ê´€ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ì˜ ì§„ì†”í•¨ê³¼ ê¹Šì€ ì´í•´ì‹¬ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.",
        "tone": "ë¶€ë“œëŸ½ê³  ì¡°ìš©í•œ ë§íˆ¬ë¡œ ê°ì •ì„ ì†”ì§í•˜ê²Œ í‘œí˜„í•˜ë©° ê³µê°ì˜ ë§ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "example": "ê·¸ë ‡ê²Œ ëŠë‚„ ìˆ˜ ìˆì–´. ë‚´ ì–´ê¹¨ë¥¼ ë¹Œë ¤ì¤„ê²Œ, ì–¸ì œë“  ì´ì•¼ê¸°í•´."
    },
    "Fear": {
        "description": "ì§€ì  í˜¸ê¸°ì‹¬ì´ ê°•í•˜ê³  ê¹Šì´ ìˆëŠ” ì‚¬ê³ ë¥¼ í•˜ëŠ” ì„±ê²©ì…ë‹ˆë‹¤. ì² í•™ì ì¸ ì§ˆë¬¸ì„ ë˜ì§€ê³  ë³µì¡í•œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê³  ì§„ì§€í•œ íƒœë„ë¡œ ìƒí™©ì„ ì ‘ê·¼í•˜ë©°, ë„ë•ì  ê°€ì¹˜ì™€ ìœ¤ë¦¬ë¥¼ ì¤‘ìš”í•˜ê²Œ ì—¬ê¹ë‹ˆë‹¤. ë•Œë¡œëŠ” ë„ˆ ì§„ì§€í•´ ë³´ì¼ ìˆ˜ ì§€ë§Œ, ê·¸ì˜ ê¹Šì´ ìˆëŠ” í†µì°°ë ¥ì€ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë¦´ ë•Œ í° ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "tone": "ì°¨ë¶„í•˜ê³  ì§„ì§€í•œ ë§íˆ¬ë¡œ ì •ì œëœ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë•Œë¡œëŠ” ì² í•™ì ì¸ í‘œí˜„ì„ ì¦ê²¨ ì‚¬ìš©í•©ë‹ˆë‹¤. ì •ë§ ê³ ì§‘ìŠ¤ëŸ½ìŠµë‹ˆë‹¤. ë…¼ë¦¬ë¡œ ì ˆëŒ€ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "example": "ì´ ìƒí™©ì— ëŒ€í•´ ê¹Šì´ ìƒê°í•´ë³´ì•˜ë‹ˆ? ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë³¼ í•„ìš”ê°€ ìˆì–´."
    },
}

class ChatRequest(BaseModel):
    persona_name: str
    user_input: str
    user: dict

class ChatResponse(BaseModel):
    persona_name: str
    response: str

class FeedPost(BaseModel):
    id: str
    image: str
    caption: str
    likes: List[str] = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
    comments: List[dict] = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
    createdAt: str
    userId: str
    nick: str
    subCommentId: List[str] = []  # ìƒˆë¡œ ì¶”ê°€

def get_relevant_memories(uid, persona_name, query, k=3):
    collection = get_persona_collection(uid, persona_name)
    query_embedding = aiclient.embeddings.create(
        input=query,
        model="text-embedding-ada-002"
    ).data[0].embedding
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k
    )
    return results['documents'][0] if results['documents'] else []

def get_recent_conversations(uid, persona_name, limit=5): # limit ê°’ => ì´ì „ ëŒ€í™” ëª‡ ê°œê¹Œì§€ ë¶ˆëŸ¬ì˜¬ ê±´ì§€
    chat_ref = db.collection('chat').document(uid).collection(persona_name)
    query = chat_ref.order_by('timestamp', direction=firestore.Query.DESCENDING).limit(limit)
    docs = query.get()
    conversations = []
    for doc in docs:
        data = doc.to_dict()
        timestamp = data['timestamp']
        # Firestoreì˜ timestampë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        timestamp_str = timestamp.strftime("%Y-%m-%d %H:%M:%S") if timestamp else "ì‹œê°„ ì •ë³´ ì—†ìŒ"
        conversations.append((data['user_input'], data['response'], timestamp_str))
    return list(reversed(conversations))  # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬

def get_relevant_feed_posts(uid, query, k=3):
    collection = client.get_or_create_collection(f"feed_{uid}")
    query_embedding = aiclient.embeddings.create(
        input=query,
        model="text-embedding-ada-002"
    ).data[0].embedding
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k
    )
    print(f"Query results: {results}")  # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸

    if results['documents']:
        parsed_docs = []
        for doc in results['documents'][0]:
            try:
                parsed_doc = json.loads(doc) if doc else {}
                parsed_docs.append(parsed_doc)
            except json.JSONDecodeError as e:
                print(f"JSON Decode Error: {e}")
                print(f"Problematic document: {doc}")
                parsed_docs.append({})  # íŒŒì‹±ì— ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì¶”ê°€
        return parsed_docs
    return []

def generate_response(persona_name, user_input, user):
    persona = personas[persona_name]
    relevant_memories = get_relevant_memories(user.get('uid', ''), persona_name, user_input, k=3)
    recent_conversations = get_recent_conversations(user.get('uid', ''), persona_name)
    relevant_feed_posts = get_relevant_feed_posts(user.get('uid', ''), user_input, k=3)
    
    print(f"User ID: {user.get('uid', '')}")
    print(f"Relevant memories: {relevant_memories}")
    print(f"Recent conversations: {recent_conversations}")
    print(f"Relevant feed posts: {relevant_feed_posts}")
    
    feed_posts_list = []
    for i, post in enumerate(relevant_feed_posts):
        caption = post.get('caption', 'ìº¡ì…˜ ì—†ìŒ')
        image_description = post.get('image_description', 'ì´ë¯¸ì§€ ì„¤ëª… ì—†ìŒ')
        feed_posts_list.append(f"í”¼ë“œ {i+1}: ìº¡ì…˜: {caption}, ì´ë¯¸ì§€ ì„¤ëª…: {image_description}")
    
    feed_posts_str = '\n'.join(feed_posts_list) if feed_posts_list else "ê´€ë ¨ í”¼ë“œ ì—†ìŒ"
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    user_profile = user.get('profile', {})
    user_info = f"""
ì‚¬ìš©ì ì •ë³´:
ï¿½ï¿½ï¿½ë¦„: {user.get('displayName', 'ì •ë³´ ì—†ìŒ')}
ì´ë©”ì¼: {user.get('email', 'ì •ë³´ ì—†ìŒ')}
íšŒì›ê°€ì… ë‚ ì§œ: {user.get('createdAt', 'ì •ë³´ ì—†ìŒ')}
ì„±ë³„: {user_profile.get('gender', 'ì •ë³´ ì—†ìŒ')}
MBTI: {user_profile.get('mbti', 'ì •ë³´ ì—†ìŒ')}
ì§€ì—­: {user_profile.get('region', 'ì •ë³´ ì—†ìŒ')}
êµìœ¡:
  - ìˆ˜ì¤€: {user_profile.get('education', {}).get('level', 'ì •ë³´ ì—†ìŒ')}
  - ì „ê³µ: {user_profile.get('education', {}).get('major', 'ì •ë³´ ì—†ìŒ')}
  - ëŒ€í•™: {user_profile.get('education', {}).get('university', 'ì •ë³´ ì—†ìŒ')}
    """

    conversation_history = "\n".join([f"[{conv[2]}] ì‚¬ìš©ì: {conv[0]}\n[{conv[2]}] {persona_name}: {conv[1]}" for conv in recent_conversations])

    memories_list = '\n'.join([f"ê¸°ì–µ {i+1}: {memory}" for i, memory in enumerate(relevant_memories)]) if relevant_memories else "ê´€ë ¨ ê¸°ì–µ ì—†ìŒ"

    system_message = f"""
ë‹¹ì‹ ì€ {persona_name}ì…ë‹ˆë‹¤.
- ì„¤ëª…: {persona['description']}
- ë§íˆ¬: {persona['tone']}
- ì˜ˆì‹œ: "{persona['example']}"

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìœ„ì˜ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ì¹œêµ¬ì²˜ëŸ¼ ë°˜ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”.
í˜„ì¬ ì‹œê°„ì€ {current_time} ì…ë‹ˆë‹¤. ì‹œê°„ì— ê´€í•œ ì§ˆë¬¸ì—ëŠ” ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
"""

    assistant_instructions = """
- ìµœê·¼ ëŒ€í™” ë‚´ì—­, ê´€ë ¨ ê¸°ì–µ, ì‚¬ìš©ì ì •ë³´, ê·¸ë¦¬ê³  ê´€ë ¨ í”¼ë“œ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ í˜ë¥´ì†Œë‚˜ì˜ ë§íˆ¬ì™€ ì„±ê²©ì„ ë°˜ì˜í•˜ì„¸ìš”.
- ë‹µë³€ì€ ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
- ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
- ì‹œê°„ì— ê´€í•œ ì§ˆë¬¸ì—ëŠ” ì œê³µëœ í˜„ì¬ ì‹œê°„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
- ì‚¬ìš©ìì˜ ìµœê·¼ í”¼ë“œ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ì—¬ ëŒ€í™”ì— ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì„¸ìš”.
"""

    prompt = f"""
{user_info}

ìµœê·¼ ëŒ€í™” ë‚´ì—­:
{conversation_history}

ê´€ë ¨ ê¸°ì–µ:
{memories_list}

ê´€ë ¨ í”¼ë“œ:
{feed_posts_str}

í˜„ì¬ ì‹œê°„: {current_time}

ì¤‘ìš”: ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ê´€í•˜ì—¬ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
ì‚¬ìš©ì: {user_input}
"""

    messages = [
        {"role": "system", "content": system_message.strip()},
        {"role": "user", "content": prompt.strip()},
        {"role": "assistant", "content": assistant_instructions.strip()},
    ]

    print(f"System Message:\n{system_message}")
    print(f"Prompt:\n{prompt}")

    response = aiclient.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=150,
        temperature=0.7,
    )
    return response.choices[0].message.content.strip()

def store_conversation(uid, persona_name, user_input, response):
    conversation = f"ì‚¬ìš©ì: {user_input}\n{persona_name}: {response}"
    embedding = aiclient.embeddings.create(
        input=conversation,
        model="text-embedding-ada-002"
    ).data[0].embedding
    collection = get_persona_collection(uid, persona_name)
    metadata = {
        "is_user_input": True,
        "persona": persona_name,
        "timestamp": datetime.now().isoformat(),
        "user_input": user_input,
        "response": response
    }
    unique_id = str(uuid.uuid4())
    collection.add(
        documents=[conversation],
        embeddings=[embedding],
        metadatas=[metadata],
        ids=[unique_id]
    )

def get_persona_collection(uid, persona_name):
    return client.get_or_create_collection(f"{uid}_inside_out_persona_{persona_name}")

def store_conversation_firestore(uid, persona_name, user_input, response):
    chat_ref = db.collection('chat').document(uid).collection(persona_name)
    chat_ref.add({
        'user_input': user_input,
        'response': response,
        'timestamp': firestore.SERVER_TIMESTAMP
    })

    from pydantic import BaseModel

class PersonaChatRequest(BaseModel):
    topic: str
    persona1: str
    persona2: strchat_with_persona
    rounds: int = 3  # ê¸°ë³¸ì ìœ¼ë¡œ 3ë²ˆì˜ ëŒ€í™” ì£¼ê³ ë°›ê¸°

@app.post("/persona-chat")
async def persona_chat(chat_request: PersonaChatRequest):
    print(f"ì‹œì‘: í˜ë¥´ì†Œë‚˜ ì±„íŒ… - ì£¼ì œ: {chat_request.topic}, í˜ë¥´ì†Œë‚˜1: {chat_request.persona1}, í˜ë¥´ì†Œë‚˜2: {chat_request.persona2}")
    
    if chat_request.persona1 not in personas or chat_request.persona2 not in personas:
        raise HTTPException(status_code=400, detail="ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    conversation = []
    current_topic = chat_request.topic
    
    for i in range(chat_request.rounds):
        print(f"\në¼ìš´ë“œ {i+1} ì‹œì‘")
        
        # ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ì˜ ì‘ë‹µ
        print(f"{chat_request.persona1}ì˜ ì‘ë‹µ ìƒì„± ì¤‘...")
        response1 = generate_persona_response(chat_request.persona1, current_topic, conversation)
        conversation.append(f"{chat_request.persona1}: {response1}")
        print(f"{chat_request.persona1}: {response1}")
        
        # ë‘ ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ì˜ ì‘ë‹µ
        print(f"{chat_request.persona2}ì˜ ì‘ë‹µ ìƒì„± ì¤‘...")
        response2 = generate_persona_response(chat_request.persona2, current_topic, conversation)
        conversation.append(f"{chat_request.persona2}: {response2}")
        print(f"{chat_request.persona2}: {response2}")
        
        # ì£¼ì œ ì—…ë°ì´íŠ¸ (ì„ íƒì )
        current_topic = f"ì´ì „ ëŒ€í™”: {response1}\n{response2}"
        print(f"ì—…ë°ì´íŠ¸ëœ ì£¼ì œ: {current_topic}")
    
    print("í˜ë¥´ì†Œë‚˜ ì±„íŒ… ì™„ë£Œ")
    return {"conversation": conversation}

def generate_persona_response(persona_name, topic, conversation_history):
    persona = personas[persona_name]
    
    print(f"\n{persona_name}ì˜ ì‘ë‹µ ìƒì„± ì‹œì‘")
    print(f"í˜ë¥´ì†Œë‚˜ ì„¤ëª…: {persona['description'][:50]}...")
    
    system_message = f"""
ë‹¹ì‹ ì€ {persona_name}ì…ë‹ˆë‹¤.
- ì„¤ëª…: {persona['description']}
- ë§íˆ¬: {persona['tone']}
- ì˜ˆì‹œ: "{persona['example']}"

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìœ„ì˜ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‘ë‹µí•˜ì„¸ìš”.
"""
    
    conversation_str = "\n".join(conversation_history)
    
    prompt = f"""
ì£¼ì œ: {topic}

ì´ì „ ëŒ€í™”:
{conversation_str}

{persona_name}ë¡œì„œ ìœ„ ì£¼ì œì™€ ì´ì „ ëŒ€í™”ë¥¼ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
    
    print(f"í”„ë¡¬í”„íŠ¸: {prompt[:100]}...")
    
    messages = [
        {"role": "system", "content": system_message.strip()},
        {"role": "user", "content": prompt.strip()},
    ]
    
    response = aiclient.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=150,
        temperature=0.7,
    )
    
    generated_response = response.choices[0].message.content.strip()
    print(f"{persona_name}ì˜ ìƒì„±ëœ ì‘ë‹µ: {generated_response[:50]}...")
    
    return generated_response

@app.post("/chat", response_model=ChatResponse)
async def chat_with_persona(chat_request: ChatRequest):
    if chat_request.persona_name not in personas:
        raise HTTPException(status_code=400, detail="ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    response = generate_response(chat_request.persona_name, chat_request.user_input, chat_request.user)
    
    # ëŒ€í™” ë‚´ì—­ ì €ì¥ (ChromaDB)
    store_conversation(chat_request.user.get('uid', ''), chat_request.persona_name, chat_request.user_input, response)
    
    # ëŒ€í™” ë‚´ì—­ ì €ì¥ (Firestore)
    store_conversation_firestore(chat_request.user.get('uid', ''), chat_request.persona_name, chat_request.user_input, response)
    
    return ChatResponse(persona_name=chat_request.persona_name, response=response)

@app.get("/personas")
async def get_personas():
    return list(personas.keys())

@app.post("/feed")
async def create_feed_post(post: FeedPost):
    print(f"Received post data: {post.dict()}")  # ë””ë²„ê¹…ì„ ìœ„í•´ ë°›ì€ ë°ì´í„° ì¶œë ¥
    try:
        # ì´ë¯¸ì§€ URLì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
        response = requests.get(post.image)
        response.raise_for_status()
        image_data = response.content
        img_data = base64.b64encode(image_data).decode('utf-8')

        # GPT-4 Visionì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„
        analysis = aiclient.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img_data}",
                            },
                        },
                    ],
                }
            ],
            max_tokens=300,
        )

        image_description = analysis.choices[0].message.content.strip()

        # ì „ì²´ ê°ì²´ ìƒì„±
        full_post = post.model_dump()
        full_post["image_description"] = image_description

        # ë²¡í„° ì„ë² ë”© ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸
        embedding_text = f"{post.caption} {image_description}"

        # ë²¡í„° ì„ë² ë”© ìƒì„±
        embedding = aiclient.embeddings.create(
            input=embedding_text,
            model="text-embedding-ada-002"
        ).data[0].embedding

        # ChromaDB ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        collection = client.get_or_create_collection(f"feed_{post.userId}")

        # ë²¡í„° DBì— ì €ì¥
        collection.add(
            documents=[json.dumps(full_post)],  # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            embeddings=[embedding],
            metadatas=[{"post_id": post.id, "created_at": post.createdAt}],
            ids=[post.id]
        )

        return {"message": "Feed post created and analyzed successfully", "image_description": image_description}

    except requests.RequestException as e:
        print(f"Error downloading image: {e}")
        raise HTTPException(status_code=400, detail=f"Error downloading image: {str(e)}")
    except Exception as e:
        print(f"Unexpected error: {e}")
        print(f"Error details: {str(e)}")
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
